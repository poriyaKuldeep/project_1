{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8fe8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca90b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"E_Commerce_Churn_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2afa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786e5a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "      <th>Tenure_update</th>\n",
       "      <th>WarehouseToHome_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004</td>\n",
       "      <td>Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50005</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>CC</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID PreferredLoginDevice  CityTier PreferredPaymentMode  Gender  \\\n",
       "0       50001                Phone         3           Debit Card  Female   \n",
       "1       50002                Phone         1                  UPI    Male   \n",
       "2       50003                Phone         1           Debit Card    Male   \n",
       "3       50004                Phone         3           Debit Card    Male   \n",
       "4       50005                Phone         1                   CC    Male   \n",
       "\n",
       "   HourSpendOnApp  NumberOfDeviceRegistered    PreferedOrderCat  \\\n",
       "0             3.0                         3  Laptop & Accessory   \n",
       "1             3.0                         4        Mobile Phone   \n",
       "2             2.0                         4        Mobile Phone   \n",
       "3             2.0                         4  Laptop & Accessory   \n",
       "4             NaN                         3        Mobile Phone   \n",
       "\n",
       "   SatisfactionScore MaritalStatus  NumberOfAddress  Complain  \\\n",
       "0                  2        Single                9         1   \n",
       "1                  3        Single                7         1   \n",
       "2                  3        Single                6         1   \n",
       "3                  5        Single                8         0   \n",
       "4                  5        Single                3         0   \n",
       "\n",
       "   OrderAmountHikeFromlastYear  CouponUsed  OrderCount  DaySinceLastOrder  \\\n",
       "0                         11.0         1.0         1.0                5.0   \n",
       "1                         15.0         0.0         1.0                0.0   \n",
       "2                         14.0         0.0         1.0                3.0   \n",
       "3                         23.0         0.0         1.0                3.0   \n",
       "4                         11.0         1.0         1.0                3.0   \n",
       "\n",
       "   CashbackAmount  Tenure_update  WarehouseToHome_update  \n",
       "0          159.93            4.0                     6.0  \n",
       "1          120.90            NaN                     8.0  \n",
       "2          120.28            NaN                    30.0  \n",
       "3          134.07            0.0                    15.0  \n",
       "4          129.60            0.0                    12.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31f459c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5d7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3941, 19), (1689, 19))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 10)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540c5320",
   "metadata": {},
   "source": [
    "<h3>Now we create some columtransformer for individual columns and after that we combine that all ColumnTransformer object into Machine Learning Pipeline.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc46c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnTransformer for one hot encoding \n",
    "num_features = df.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = df.select_dtypes(include=\"object\").columns\n",
    "\n",
    "trf1=ColumnTransformer(transformers=[\n",
    "    ('one_hot' , OneHotEncoder(sparse_output=False,handle_unknown=\"ignore\" ) ,cat_features)\n",
    "],remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9135ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.  ,   1.  ,   0.  , ..., 208.55,  13.  ,  10.  ],\n",
       "       [  0.  ,   1.  ,   1.  , ..., 160.91,   2.  ,   8.  ],\n",
       "       [  1.  ,   0.  ,   1.  , ..., 151.55,  12.  ,  14.  ],\n",
       "       ...,\n",
       "       [  0.  ,   1.  ,   1.  , ..., 144.04,   7.  ,  14.  ],\n",
       "       [  0.  ,   1.  ,   0.  , ..., 148.4 ,   1.  ,  31.  ],\n",
       "       [  0.  ,   1.  ,   1.  , ..., 186.33,  20.  ,  31.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trf1.fit_transform(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47614067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnTransformer for handling Missing values\n",
    "\n",
    "trf2=ColumnTransformer([\n",
    "    ('KNNimputer' ,KNNImputer(n_neighbors=5),slice(32) )\n",
    "    \n",
    "],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5078960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnTransformer for feature scalling\n",
    "\n",
    "trf3=ColumnTransformer([\n",
    "    ('scale' , StandardScaler() ,[] )\n",
    "],remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6b3523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ColumnTransformer for feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfbb2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier=RandomForestClassifier(random_state=10)\n",
    "lr_classifier=LogisticRegression()\n",
    "dt_classifier=DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf = 5)\n",
    "Ab_classifier=AdaBoostClassifier(n_estimators=100)\n",
    "sv_classifier=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b38694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr=Pipeline([\n",
    "    (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"trf4\",lr_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "018943e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf=Pipeline([\n",
    "    (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"trf4\",rf_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3432b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([\n",
    "    (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"trf4\",dt_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e41f0b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_Ab=Pipeline([\n",
    "    (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"trf4\",Ab_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8fedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sv=Pipeline([\n",
    "    (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"trf4\",sv_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "399b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LEts make the list of pipelines\n",
    "\n",
    "pipelines = [pipeline_Ab,pipeline_dt,pipeline_lr,pipeline_rf,pipeline_sv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f38e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "pipe_dict = {0: 'AdaBoost', 1: 'Decision Tree', 2: 'Logistic Regression' , 3: 'RandomForest',4:'svc'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3305f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Test Accuracy: 0.8851391355831854\n",
      "Decision Tree Test Accuracy: 0.8691533451746596\n",
      "Logistic Regression Test Accuracy: 0.8507992895204263\n",
      "RandomForest Test Accuracy: 0.9473060982830077\n",
      "svc Test Accuracy: 0.8176435760805211\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a13b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy=0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2aa9870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy  : RandomForest\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(x_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(x_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print('Classifier with best accuracy  : {}'.format(pipe_dict[best_classifier]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4b5dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost cross val accuracy 0.896726563857096\n",
      "Decision Tree cross val accuracy 0.8759227448482626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression cross val accuracy 0.8530849304845175\n",
      "RandomForest cross val accuracy 0.9393545772133329\n",
      "svc cross val accuracy 0.8376046270740447\n"
     ]
    }
   ],
   "source": [
    "for i,pipe in enumerate(pipelines ):\n",
    " cvscore=cross_val_score(pipe,x_train,y_train,cv=5,scoring=\"accuracy\").mean()\n",
    " print (f\"{pipe_dict[i]} cross val accuracy {cvscore}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a1dbe",
   "metadata": {},
   "source": [
    "<h3>Pipelines Perform Hyperparameter Tuning Using Grid SearchCV</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d4cde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e60d7234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "50 fits failed out of a total of 3540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.85384571        nan 0.84953195        nan 0.84927815        nan\n",
      " 0.84674007        nan 0.84953195        nan 0.84877053        nan\n",
      " 0.84953195        nan 0.84978576        nan 0.84978544        nan\n",
      " 0.85206713        nan 0.89520436 0.83760463 0.83760463 0.84141206\n",
      " 0.89469643 0.83760463 0.83760463 0.84014302 0.89520436 0.83760463\n",
      " 0.83760463 0.84014302 0.89495088 0.83760463 0.83760463 0.84014302\n",
      " 0.89495088 0.83760463 0.83760463 0.84014302 0.89495088 0.83760463\n",
      " 0.83760463 0.84014302 0.89495088 0.83760463 0.83760463 0.84014302\n",
      " 0.89495088 0.83760463 0.83760463 0.84014302 0.89495088 0.83760463\n",
      " 0.83760463 0.84014302 0.89495088 0.83760463 0.83760463 0.84014302\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83836508 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.85409887 0.84166554 0.84623021 0.84242664 0.8426798  0.84597672\n",
      " 0.84801008 0.84420297 0.84470962 0.84344026 0.84496375 0.84420136\n",
      " 0.85587231 0.84420136 0.84597672 0.84369568 0.84572324 0.8449631\n",
      " 0.84699549 0.84293393 0.84470962 0.84546943 0.84344155 0.8434409\n",
      " 0.84420361 0.84369342 0.84369471 0.84267852 0.84394723 0.844202\n",
      " 0.84877021 0.83861953 0.83785843 0.83760463 0.83785843 0.83760463\n",
      " 0.86196271 0.86475137 0.86246743 0.85967812 0.86120097 0.85942464\n",
      " 0.8662755  0.85815432 0.86246968 0.86018606 0.86120065 0.85840973\n",
      " 0.85841134 0.8596778  0.8581556  0.85917148 0.85942432 0.85866354\n",
      " 0.86602169 0.85917051 0.85917276 0.86170923 0.85967845 0.85841038\n",
      " 0.86043987 0.85840845 0.8563796  0.85993225 0.86069368 0.85942464\n",
      " 0.84749828 0.84318742 0.84217219 0.84039586 0.84014238 0.84014238\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.85054557 0.84445613 0.84623053 0.84470865 0.84445581 0.8434409\n",
      " 0.84268077 0.8439482  0.84547007 0.8447093  0.84394884 0.84496214\n",
      " 0.84217315 0.84495956 0.84648305 0.84268077 0.84496246 0.84470962\n",
      " 0.8444497  0.84369568 0.84496246 0.84470994 0.8431871  0.84369503\n",
      " 0.84496246 0.84572517 0.84496182 0.84546814 0.84445549 0.84293329\n",
      " 0.83963315 0.83760463 0.83785811 0.83811224 0.83760463 0.83760463\n",
      " 0.85486094 0.86373936 0.8581556  0.85790115 0.85967909 0.86043922\n",
      " 0.8609462  0.8609478  0.85967812 0.86018606 0.85866386 0.85967877\n",
      " 0.86246582 0.85790373 0.85764767 0.85790115 0.85840941 0.86043955\n",
      " 0.86145542 0.85764895 0.86120161 0.86018831 0.8622162  0.86145477\n",
      " 0.86170697 0.85790083 0.86094877 0.86120097 0.86043987 0.86069432\n",
      " 0.84090348 0.84242696 0.84014205 0.83988857 0.84115664 0.84014238\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.85105383 0.84293232 0.84420265 0.84318806 0.84420168 0.84546975\n",
      " 0.84749731 0.84724512 0.84648337 0.84090315 0.84293297 0.84572356\n",
      " 0.84141173 0.84699099 0.84166425 0.84343962 0.8434409  0.84369407\n",
      " 0.84140948 0.84800686 0.8449631  0.84191903 0.84394852 0.8452153\n",
      " 0.84217283 0.84268013 0.84648498 0.84166425 0.844202   0.84445613\n",
      " 0.84597865 0.83912715 0.83760463 0.83836605 0.83760463 0.83760463\n",
      " 0.8695766  0.86120097 0.85993161 0.86297762 0.85967909 0.8601851\n",
      " 0.85739386 0.8599329  0.86323175 0.86043987 0.86094684 0.8601851\n",
      " 0.86043987 0.86043955 0.85815625 0.86323014 0.86069271 0.85866322\n",
      " 0.86120225 0.85917308 0.86145477 0.85917051 0.86043987 0.85942464\n",
      " 0.86323078 0.85993225 0.8617089  0.8622162  0.86018703 0.86145445\n",
      " 0.84369182 0.84419943 0.84039618 0.83938096 0.83988825 0.84039586\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.85104868 0.84800654 0.84217187 0.84318742 0.84369278 0.84496214\n",
      " 0.84293458 0.8462286  0.84293329 0.84673654 0.84420168 0.8449631\n",
      " 0.84572034 0.84851351 0.8426798  0.84597511 0.84521562 0.84521691\n",
      " 0.84673718 0.845472   0.84166393 0.84496407 0.84445517 0.84470962\n",
      " 0.84826163 0.84470865 0.84344123 0.84521755 0.8439482  0.844202\n",
      " 0.84141045 0.83861986 0.83760463 0.83760463 0.83785843 0.83760463\n",
      " 0.86246936 0.86221491 0.85967845 0.86449949 0.860694   0.85942464\n",
      " 0.85993065 0.85891767 0.86018638 0.86145445 0.86170923 0.86018606\n",
      " 0.8660233  0.85739483 0.85866354 0.86196175 0.86069368 0.85942432\n",
      " 0.86602073 0.8629789  0.86196207 0.86196239 0.86145413 0.86120032\n",
      " 0.86779738 0.85714134 0.85917148 0.85942496 0.86069303 0.86120032\n",
      " 0.85028823 0.83887366 0.84115696 0.84039651 0.84039554 0.83988857\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.85028726 0.84267948 0.84724415 0.84318774 0.84420297 0.84242632\n",
      " 0.84140948 0.8457242  0.84242664 0.84394852 0.8439482  0.84496214\n",
      " 0.8495326  0.84191774 0.84344187 0.84115696 0.844202   0.84496182\n",
      " 0.84801072 0.84369182 0.84242471 0.84090315 0.8434409  0.8431871\n",
      " 0.84521659 0.84470962 0.84318581 0.84268013 0.84470865 0.84394787\n",
      " 0.83912747 0.83811224 0.83887366 0.83811224 0.83760463 0.83760463\n",
      " 0.86805151 0.86145477 0.8622162  0.85942464 0.86196207 0.86170826\n",
      " 0.86348362 0.86221523 0.86094748 0.86043955 0.86094716 0.86018574\n",
      " 0.86069625 0.860694   0.8601851  0.86170858 0.86272349 0.86221587\n",
      " 0.86171083 0.86018799 0.85815753 0.85815432 0.86272381 0.86069368\n",
      " 0.86247225 0.86043955 0.86145381 0.86196175 0.86120129 0.86094813\n",
      " 0.84547329 0.84039651 0.84115664 0.8409038  0.84064999 0.83938096\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463 0.83760463\n",
      " 0.84851737 0.84572645 0.84470833 0.84318581 0.84521498 0.844202\n",
      " 0.85079745 0.84369503 0.84546943 0.8447093  0.84191838 0.84445549\n",
      " 0.84496503 0.84344026 0.84546975 0.8434393  0.84724512 0.8449631\n",
      " 0.84699034 0.84065031 0.84420072 0.84217315 0.84521659 0.84496278\n",
      " 0.84318549 0.84445485 0.84369375 0.8431871  0.844202   0.8434409\n",
      " 0.84191517 0.83760463 0.83785843 0.83811224 0.83760463 0.83760463\n",
      " 0.86627614 0.86119936 0.86069335 0.85942528 0.85942367 0.86018606\n",
      " 0.85866225 0.8617073  0.85942303 0.86170826 0.86043955 0.86120032\n",
      " 0.86576596 0.86246968 0.86196207 0.86247032 0.8617089  0.86094684\n",
      " 0.86805086 0.86348587 0.86272445 0.86120097 0.85917148 0.8609478\n",
      " 0.86272413 0.86069561 0.8609462  0.86094684 0.86069368 0.86094748\n",
      " 0.84344219 0.83988825 0.84014238 0.83912715 0.84166425 0.84115728]\n",
      "  warnings.warn(\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\High-Tech\\Documents\\AI\\project_1\\venv\\lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([ \n",
    "     (\"trf1\",trf1),\n",
    "    (\"trf2\",trf2),\n",
    "    (\"trf3\",trf3),\n",
    "    (\"classifier\", RandomForestClassifier())\n",
    "    ])\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2','l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10,50,150,100,500, 1000],\n",
    "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e526a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6840c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
